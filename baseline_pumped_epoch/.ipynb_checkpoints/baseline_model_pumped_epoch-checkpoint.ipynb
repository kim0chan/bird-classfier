{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eeb8caf2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kyc_o\\anaconda3\\envs\\dl\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: \n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device('cuda' if USE_CUDA else 'cpu')\n",
    "print(DEVICE)\n",
    "\n",
    "BATCH_SIZE = 224\n",
    "EPOCH = 50\n",
    "# PUMPED EPOCH.\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "transform_base = transforms.Compose([transforms.Resize((64, 64)), transforms.ToTensor()])\n",
    "\n",
    "train_dataset = ImageFolder(root='../dataset/train', transform=transform_base)\n",
    "val_dataset = ImageFolder(root='../dataset/valid', transform=transform_base)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62e18963",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        \n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding = 1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding = 1)\n",
    "        self.conv3 = nn.Conv2d(64, 64, 3, padding = 1)\n",
    "        \n",
    "        self.fc1 = nn.Linear(4096, 512)\n",
    "        self.fc2 = nn.Linear(512, 450)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = F.dropout(x, p=0.25, training=self.training)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = F.dropout(x, p=0.25, training=self.training)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = F.dropout(x, p=0.25, training=self.training)\n",
    "        \n",
    "        x = x.view(-1, 4096)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "model_base = Net().to(DEVICE)\n",
    "optimizer = optim.Adam(model_base.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f36d902",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63d27846",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "            output = model(data)\n",
    "            \n",
    "            \n",
    "            test_loss += F.cross_entropy(output, target, reduction='sum').item()\n",
    "            \n",
    "            \n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            \n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "        return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20176804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- epoch 1 ----------------\n",
      "train. Loss: 5.1053, Accuracy: 5.55%\n",
      "valid. Loss: 5.0339, Accuracy: 5.02%\n",
      "Completed in 1m 6s\n",
      "-------------- epoch 2 ----------------\n",
      "train. Loss: 3.8374, Accuracy: 23.45%\n",
      "valid. Loss: 3.6949, Accuracy: 25.64%\n",
      "Completed in 0m 59s\n",
      "-------------- epoch 3 ----------------\n",
      "train. Loss: 3.1353, Accuracy: 34.81%\n",
      "valid. Loss: 3.0042, Accuracy: 34.89%\n",
      "Completed in 0m 60s\n",
      "-------------- epoch 4 ----------------\n",
      "train. Loss: 2.7593, Accuracy: 41.24%\n",
      "valid. Loss: 2.6014, Accuracy: 41.91%\n",
      "Completed in 1m 2s\n",
      "-------------- epoch 5 ----------------\n",
      "train. Loss: 2.4612, Accuracy: 47.69%\n",
      "valid. Loss: 2.3752, Accuracy: 47.24%\n",
      "Completed in 0m 60s\n",
      "-------------- epoch 6 ----------------\n",
      "train. Loss: 2.2260, Accuracy: 52.72%\n",
      "valid. Loss: 2.1340, Accuracy: 51.96%\n",
      "Completed in 0m 59s\n",
      "-------------- epoch 7 ----------------\n",
      "train. Loss: 2.0388, Accuracy: 56.30%\n",
      "valid. Loss: 1.9775, Accuracy: 54.89%\n",
      "Completed in 0m 57s\n",
      "-------------- epoch 8 ----------------\n",
      "train. Loss: 1.9564, Accuracy: 57.42%\n",
      "valid. Loss: 1.9101, Accuracy: 55.64%\n",
      "Completed in 0m 57s\n",
      "-------------- epoch 9 ----------------\n",
      "train. Loss: 1.8149, Accuracy: 59.79%\n",
      "valid. Loss: 1.7992, Accuracy: 57.56%\n",
      "Completed in 0m 57s\n",
      "-------------- epoch 10 ----------------\n",
      "train. Loss: 1.7523, Accuracy: 62.00%\n",
      "valid. Loss: 1.7519, Accuracy: 59.16%\n",
      "Completed in 0m 58s\n",
      "-------------- epoch 11 ----------------\n",
      "train. Loss: 1.6352, Accuracy: 64.61%\n",
      "valid. Loss: 1.6756, Accuracy: 60.04%\n",
      "Completed in 0m 60s\n",
      "-------------- epoch 12 ----------------\n",
      "train. Loss: 1.5438, Accuracy: 65.89%\n",
      "valid. Loss: 1.5983, Accuracy: 61.69%\n",
      "Completed in 1m 1s\n",
      "-------------- epoch 13 ----------------\n",
      "train. Loss: 1.4646, Accuracy: 67.77%\n",
      "valid. Loss: 1.5524, Accuracy: 64.00%\n",
      "Completed in 1m 5s\n",
      "-------------- epoch 14 ----------------\n",
      "train. Loss: 1.4187, Accuracy: 68.45%\n",
      "valid. Loss: 1.5090, Accuracy: 63.07%\n",
      "Completed in 0m 57s\n",
      "-------------- epoch 15 ----------------\n",
      "train. Loss: 1.3554, Accuracy: 70.56%\n",
      "valid. Loss: 1.4816, Accuracy: 65.64%\n",
      "Completed in 0m 57s\n",
      "-------------- epoch 16 ----------------\n",
      "train. Loss: 1.3256, Accuracy: 71.32%\n",
      "valid. Loss: 1.4662, Accuracy: 65.91%\n",
      "Completed in 0m 57s\n",
      "-------------- epoch 17 ----------------\n",
      "train. Loss: 1.2740, Accuracy: 72.28%\n",
      "valid. Loss: 1.4428, Accuracy: 65.96%\n",
      "Completed in 0m 58s\n",
      "-------------- epoch 18 ----------------\n",
      "train. Loss: 1.2288, Accuracy: 73.35%\n",
      "valid. Loss: 1.4239, Accuracy: 65.33%\n",
      "Completed in 0m 57s\n",
      "-------------- epoch 19 ----------------\n",
      "train. Loss: 1.1931, Accuracy: 73.35%\n",
      "valid. Loss: 1.4142, Accuracy: 65.33%\n",
      "Completed in 0m 57s\n",
      "-------------- epoch 20 ----------------\n",
      "train. Loss: 1.1334, Accuracy: 75.01%\n",
      "valid. Loss: 1.3644, Accuracy: 67.07%\n",
      "Completed in 1m 3s\n",
      "-------------- epoch 21 ----------------\n",
      "train. Loss: 1.1281, Accuracy: 75.32%\n",
      "valid. Loss: 1.3535, Accuracy: 66.89%\n",
      "Completed in 1m 5s\n",
      "-------------- epoch 22 ----------------\n",
      "train. Loss: 1.0864, Accuracy: 76.56%\n",
      "valid. Loss: 1.3331, Accuracy: 68.22%\n",
      "Completed in 1m 5s\n",
      "-------------- epoch 23 ----------------\n",
      "train. Loss: 1.0871, Accuracy: 77.18%\n",
      "valid. Loss: 1.3529, Accuracy: 67.51%\n",
      "Completed in 1m 5s\n",
      "-------------- epoch 24 ----------------\n",
      "train. Loss: 1.0235, Accuracy: 78.18%\n",
      "valid. Loss: 1.3149, Accuracy: 68.36%\n",
      "Completed in 1m 5s\n",
      "-------------- epoch 25 ----------------\n",
      "train. Loss: 0.9680, Accuracy: 78.85%\n",
      "valid. Loss: 1.2906, Accuracy: 68.22%\n",
      "Completed in 1m 3s\n",
      "-------------- epoch 26 ----------------\n",
      "train. Loss: 0.9472, Accuracy: 79.93%\n",
      "valid. Loss: 1.2773, Accuracy: 69.69%\n",
      "Completed in 1m 4s\n",
      "-------------- epoch 27 ----------------\n",
      "train. Loss: 0.9427, Accuracy: 80.07%\n",
      "valid. Loss: 1.2716, Accuracy: 69.87%\n",
      "Completed in 1m 7s\n",
      "-------------- epoch 28 ----------------\n",
      "train. Loss: 0.9227, Accuracy: 80.46%\n",
      "valid. Loss: 1.2665, Accuracy: 68.62%\n",
      "Completed in 1m 17s\n",
      "-------------- epoch 29 ----------------\n",
      "train. Loss: 0.8628, Accuracy: 81.39%\n",
      "valid. Loss: 1.2223, Accuracy: 70.00%\n",
      "Completed in 1m 27s\n",
      "-------------- epoch 30 ----------------\n",
      "train. Loss: 0.8775, Accuracy: 81.04%\n",
      "valid. Loss: 1.2497, Accuracy: 69.47%\n",
      "Completed in 1m 21s\n",
      "-------------- epoch 31 ----------------\n",
      "train. Loss: 0.8741, Accuracy: 81.19%\n",
      "valid. Loss: 1.2558, Accuracy: 69.69%\n",
      "Completed in 1m 17s\n",
      "-------------- epoch 32 ----------------\n",
      "train. Loss: 0.8208, Accuracy: 82.70%\n",
      "valid. Loss: 1.2197, Accuracy: 70.04%\n",
      "Completed in 1m 35s\n",
      "-------------- epoch 33 ----------------\n",
      "train. Loss: 0.8148, Accuracy: 81.94%\n",
      "valid. Loss: 1.2185, Accuracy: 69.78%\n",
      "Completed in 1m 33s\n",
      "-------------- epoch 34 ----------------\n",
      "train. Loss: 0.8363, Accuracy: 82.14%\n",
      "valid. Loss: 1.2358, Accuracy: 70.13%\n",
      "Completed in 1m 21s\n",
      "-------------- epoch 35 ----------------\n",
      "train. Loss: 0.7678, Accuracy: 83.93%\n",
      "valid. Loss: 1.1996, Accuracy: 70.18%\n",
      "Completed in 1m 2s\n",
      "-------------- epoch 36 ----------------\n",
      "train. Loss: 0.7611, Accuracy: 83.62%\n",
      "valid. Loss: 1.2107, Accuracy: 69.91%\n",
      "Completed in 1m 1s\n",
      "-------------- epoch 37 ----------------\n",
      "train. Loss: 0.7394, Accuracy: 84.32%\n",
      "valid. Loss: 1.1923, Accuracy: 71.24%\n",
      "Completed in 1m 1s\n",
      "-------------- epoch 38 ----------------\n",
      "train. Loss: 0.7221, Accuracy: 84.11%\n",
      "valid. Loss: 1.1782, Accuracy: 70.53%\n",
      "Completed in 1m 1s\n",
      "-------------- epoch 39 ----------------\n",
      "train. Loss: 0.6823, Accuracy: 85.90%\n",
      "valid. Loss: 1.1643, Accuracy: 71.87%\n",
      "Completed in 1m 1s\n",
      "-------------- epoch 40 ----------------\n",
      "train. Loss: 0.7364, Accuracy: 84.94%\n",
      "valid. Loss: 1.2097, Accuracy: 70.58%\n",
      "Completed in 1m 1s\n",
      "-------------- epoch 41 ----------------\n",
      "train. Loss: 0.7389, Accuracy: 84.36%\n",
      "valid. Loss: 1.2161, Accuracy: 70.53%\n",
      "Completed in 1m 4s\n",
      "-------------- epoch 42 ----------------\n",
      "train. Loss: 0.6540, Accuracy: 86.23%\n",
      "valid. Loss: 1.1654, Accuracy: 71.42%\n",
      "Completed in 1m 1s\n",
      "-------------- epoch 43 ----------------\n",
      "train. Loss: 0.6787, Accuracy: 85.00%\n",
      "valid. Loss: 1.1752, Accuracy: 70.76%\n",
      "Completed in 1m 2s\n",
      "-------------- epoch 44 ----------------\n",
      "train. Loss: 0.6725, Accuracy: 85.27%\n",
      "valid. Loss: 1.1695, Accuracy: 71.51%\n",
      "Completed in 1m 2s\n",
      "-------------- epoch 45 ----------------\n",
      "train. Loss: 0.6034, Accuracy: 87.14%\n",
      "valid. Loss: 1.1225, Accuracy: 71.87%\n",
      "Completed in 1m 1s\n",
      "-------------- epoch 46 ----------------\n",
      "train. Loss: 0.6362, Accuracy: 86.78%\n",
      "valid. Loss: 1.1582, Accuracy: 72.04%\n",
      "Completed in 1m 1s\n",
      "-------------- epoch 47 ----------------\n",
      "train. Loss: 0.6033, Accuracy: 87.95%\n",
      "valid. Loss: 1.1402, Accuracy: 72.27%\n",
      "Completed in 1m 1s\n",
      "-------------- epoch 48 ----------------\n",
      "train. Loss: 0.5662, Accuracy: 88.60%\n",
      "valid. Loss: 1.1371, Accuracy: 72.76%\n",
      "Completed in 1m 1s\n",
      "-------------- epoch 49 ----------------\n",
      "train. Loss: 0.5702, Accuracy: 88.27%\n",
      "valid. Loss: 1.1167, Accuracy: 72.53%\n",
      "Completed in 1m 1s\n",
      "-------------- epoch 50 ----------------\n",
      "train. Loss: 0.5864, Accuracy: 87.75%\n",
      "valid. Loss: 1.1274, Accuracy: 71.96%\n",
      "Completed in 1m 2s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import copy\n",
    " \n",
    "def train_baseline(model ,train_loader, val_loader, optimizer, num_epochs = 30):\n",
    "    best_acc = 0.0  \n",
    "    best_model_wts = copy.deepcopy(model.state_dict()) \n",
    " \n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        since = time.time()  \n",
    "        train(model, train_loader, optimizer)\n",
    "        train_loss, train_acc = evaluate(model, train_loader) \n",
    "        val_loss, val_acc = evaluate(model, val_loader)\n",
    "        \n",
    "        if val_acc > best_acc: \n",
    "            best_acc = val_acc \n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        \n",
    "        time_elapsed = time.time() - since \n",
    "        print('-------------- epoch {} ----------------'.format(epoch))\n",
    "        print('train. Loss: {:.4f}, Accuracy: {:.2f}%'.format(train_loss, train_acc))   \n",
    "        print('valid. Loss: {:.4f}, Accuracy: {:.2f}%'.format(val_loss, val_acc))\n",
    "        print('Completed in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60)) \n",
    "    model.load_state_dict(best_model_wts)  \n",
    "    return model\n",
    " \n",
    "\n",
    "base = train_baseline(model_base, train_loader, val_loader, optimizer, EPOCH)  \t #(16)\n",
    "torch.save(base,'baseline.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76568ebd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17516\\555056709.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'./dataset'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m image_datasets = {x: ImageFolder(root = os.path.join(data_dir, x),\n\u001b[1;32m---> 20\u001b[1;33m                                 transform=data_tansforms[x]) for x in ['train', 'valid']}\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[0mdataloaders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_datasets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'valid'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mdataset_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_datasets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'valid'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17516\\555056709.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'./dataset'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m image_datasets = {x: ImageFolder(root = os.path.join(data_dir, x),\n\u001b[1;32m---> 20\u001b[1;33m                                 transform=data_tansforms[x]) for x in ['train', 'valid']}\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[0mdataloaders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_datasets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'valid'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mdataset_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_datasets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'valid'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize([64, 64]),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.RandomCrop(52),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'valid': transforms.Compose([\n",
    "        transforms.Resize([64, 64]),\n",
    "        transforms.RandomCrop(52),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "data_dir = './dataset'\n",
    "image_datasets = {x: ImageFolder(root = os.path.join(data_dir, x),\n",
    "                                transform=data_tansforms[x]) for x in ['train', 'valid']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=BATCH_SIZE, shuffle=True, num_workers=4) for x in ['train', 'valid']} \n",
    "dataset_size = {x: len(image_datasets[x]) for x in ['train', 'valid']}\n",
    "\n",
    "class_name = image_datasets['train'].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf756c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
