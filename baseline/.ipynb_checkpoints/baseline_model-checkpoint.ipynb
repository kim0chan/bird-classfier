{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eeb8caf2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 지정된 경로를 찾을 수 없습니다: './dataset/train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17516\\1144513904.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mtransform_base\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCompose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mResize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mtrain_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImageFolder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'./dataset/train'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtransform_base\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mval_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImageFolder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'./dataset/valid'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtransform_base\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dl\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[0;32m    314\u001b[0m             \u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m             \u001b[0mtarget_transform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m             \u001b[0mis_valid_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_valid_file\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    317\u001b[0m         )\n\u001b[0;32m    318\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dl\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[0;32m    143\u001b[0m     ) -> None:\n\u001b[0;32m    144\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m         \u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    146\u001b[0m         \u001b[0msamples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dl\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[1;34m(self, directory)\u001b[0m\n\u001b[0;32m    217\u001b[0m             \u001b[1;33m(\u001b[0m\u001b[0mTuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mall\u001b[0m \u001b[0mclasses\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0mmapping\u001b[0m \u001b[0meach\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mto\u001b[0m \u001b[0man\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m         \"\"\"\n\u001b[1;32m--> 219\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    220\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dl\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[1;34m(directory)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[0mSee\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;32mclass\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDatasetFolder\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdetails\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \"\"\"\n\u001b[1;32m---> 41\u001b[1;33m     \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Couldn't find any class folder in {directory}.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] 지정된 경로를 찾을 수 없습니다: './dataset/train'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device('cuda' if USE_CUDA else 'cpu')\n",
    "print(DEVICE)\n",
    "\n",
    "BATCH_SIZE = 224\n",
    "EPOCH = 30\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "transform_base = transforms.Compose([transforms.Resize((64, 64)), transforms.ToTensor()])\n",
    "\n",
    "train_dataset = ImageFolder(root='../dataset/train', transform=transform_base)\n",
    "val_dataset = ImageFolder(root='../dataset/valid', transform=transform_base)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62e18963",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        \n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding = 1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding = 1)\n",
    "        self.conv3 = nn.Conv2d(64, 64, 3, padding = 1)\n",
    "        \n",
    "        self.fc1 = nn.Linear(4096, 512)\n",
    "        self.fc2 = nn.Linear(512, 450)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = F.dropout(x, p=0.25, training=self.training)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = F.dropout(x, p=0.25, training=self.training)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = F.dropout(x, p=0.25, training=self.training)\n",
    "        \n",
    "        x = x.view(-1, 4096)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "model_base = Net().to(DEVICE)\n",
    "optimizer = optim.Adam(model_base.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f36d902",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63d27846",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "            output = model(data)\n",
    "            \n",
    "            \n",
    "            test_loss += F.cross_entropy(output, target, reduction='sum').item()\n",
    "            \n",
    "            \n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            \n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "        return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20176804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- epoch 1 ----------------\n",
      "train. Loss: 4.4294, Accuracy: 14.33%\n",
      "valid. Loss: 4.3355, Accuracy: 14.71%\n",
      "Completed in 0m 58s\n",
      "-------------- epoch 2 ----------------\n",
      "train. Loss: 3.1777, Accuracy: 34.09%\n",
      "valid. Loss: 3.0201, Accuracy: 34.27%\n",
      "Completed in 0m 56s\n",
      "-------------- epoch 3 ----------------\n",
      "train. Loss: 2.7054, Accuracy: 43.25%\n",
      "valid. Loss: 2.5589, Accuracy: 44.36%\n",
      "Completed in 0m 56s\n",
      "-------------- epoch 4 ----------------\n",
      "train. Loss: 2.2388, Accuracy: 52.13%\n",
      "valid. Loss: 2.1472, Accuracy: 51.87%\n",
      "Completed in 0m 56s\n",
      "-------------- epoch 5 ----------------\n",
      "train. Loss: 2.0219, Accuracy: 56.29%\n",
      "valid. Loss: 1.9648, Accuracy: 54.98%\n",
      "Completed in 0m 56s\n",
      "-------------- epoch 6 ----------------\n",
      "train. Loss: 1.8230, Accuracy: 61.03%\n",
      "valid. Loss: 1.8225, Accuracy: 58.13%\n",
      "Completed in 0m 56s\n",
      "-------------- epoch 7 ----------------\n",
      "train. Loss: 1.6194, Accuracy: 64.34%\n",
      "valid. Loss: 1.6485, Accuracy: 60.18%\n",
      "Completed in 0m 56s\n",
      "-------------- epoch 8 ----------------\n",
      "train. Loss: 1.4960, Accuracy: 66.84%\n",
      "valid. Loss: 1.5936, Accuracy: 61.29%\n",
      "Completed in 0m 56s\n",
      "-------------- epoch 9 ----------------\n",
      "train. Loss: 1.4137, Accuracy: 69.63%\n",
      "valid. Loss: 1.5355, Accuracy: 63.38%\n",
      "Completed in 0m 56s\n",
      "-------------- epoch 10 ----------------\n",
      "train. Loss: 1.2893, Accuracy: 71.15%\n",
      "valid. Loss: 1.4372, Accuracy: 64.89%\n",
      "Completed in 0m 56s\n",
      "-------------- epoch 11 ----------------\n",
      "train. Loss: 1.2025, Accuracy: 73.50%\n",
      "valid. Loss: 1.3969, Accuracy: 66.36%\n",
      "Completed in 0m 56s\n",
      "-------------- epoch 12 ----------------\n",
      "train. Loss: 1.1236, Accuracy: 75.15%\n",
      "valid. Loss: 1.3564, Accuracy: 66.98%\n",
      "Completed in 0m 56s\n",
      "-------------- epoch 13 ----------------\n",
      "train. Loss: 1.0651, Accuracy: 76.99%\n",
      "valid. Loss: 1.3304, Accuracy: 68.13%\n",
      "Completed in 0m 56s\n",
      "-------------- epoch 14 ----------------\n",
      "train. Loss: 0.9825, Accuracy: 79.04%\n",
      "valid. Loss: 1.3052, Accuracy: 68.44%\n",
      "Completed in 0m 58s\n",
      "-------------- epoch 15 ----------------\n",
      "train. Loss: 0.9596, Accuracy: 79.87%\n",
      "valid. Loss: 1.3050, Accuracy: 68.67%\n",
      "Completed in 0m 57s\n",
      "-------------- epoch 16 ----------------\n",
      "train. Loss: 0.9461, Accuracy: 79.48%\n",
      "valid. Loss: 1.2846, Accuracy: 69.56%\n",
      "Completed in 0m 56s\n",
      "-------------- epoch 17 ----------------\n",
      "train. Loss: 0.8751, Accuracy: 80.50%\n",
      "valid. Loss: 1.2499, Accuracy: 69.51%\n",
      "Completed in 0m 56s\n",
      "-------------- epoch 18 ----------------\n",
      "train. Loss: 0.7920, Accuracy: 83.20%\n",
      "valid. Loss: 1.2223, Accuracy: 70.22%\n",
      "Completed in 0m 56s\n",
      "-------------- epoch 19 ----------------\n",
      "train. Loss: 0.7752, Accuracy: 83.62%\n",
      "valid. Loss: 1.2178, Accuracy: 70.89%\n",
      "Completed in 0m 56s\n",
      "-------------- epoch 20 ----------------\n",
      "train. Loss: 0.7400, Accuracy: 84.71%\n",
      "valid. Loss: 1.2108, Accuracy: 69.29%\n",
      "Completed in 0m 56s\n",
      "-------------- epoch 21 ----------------\n",
      "train. Loss: 0.7018, Accuracy: 85.17%\n",
      "valid. Loss: 1.1892, Accuracy: 70.93%\n",
      "Completed in 0m 56s\n",
      "-------------- epoch 22 ----------------\n",
      "train. Loss: 0.6753, Accuracy: 85.93%\n",
      "valid. Loss: 1.1549, Accuracy: 71.87%\n",
      "Completed in 0m 56s\n",
      "-------------- epoch 23 ----------------\n",
      "train. Loss: 0.6540, Accuracy: 86.57%\n",
      "valid. Loss: 1.1979, Accuracy: 70.76%\n",
      "Completed in 0m 56s\n",
      "-------------- epoch 24 ----------------\n",
      "train. Loss: 0.6305, Accuracy: 86.92%\n",
      "valid. Loss: 1.1494, Accuracy: 71.33%\n",
      "Completed in 0m 56s\n",
      "-------------- epoch 25 ----------------\n",
      "train. Loss: 0.5849, Accuracy: 88.23%\n",
      "valid. Loss: 1.1211, Accuracy: 71.91%\n",
      "Completed in 0m 57s\n",
      "-------------- epoch 26 ----------------\n",
      "train. Loss: 0.5858, Accuracy: 88.00%\n",
      "valid. Loss: 1.1152, Accuracy: 71.78%\n",
      "Completed in 0m 57s\n",
      "-------------- epoch 27 ----------------\n",
      "train. Loss: 0.5126, Accuracy: 89.67%\n",
      "valid. Loss: 1.1037, Accuracy: 72.18%\n",
      "Completed in 0m 57s\n",
      "-------------- epoch 28 ----------------\n",
      "train. Loss: 0.5210, Accuracy: 89.61%\n",
      "valid. Loss: 1.1303, Accuracy: 71.73%\n",
      "Completed in 0m 56s\n",
      "-------------- epoch 29 ----------------\n",
      "train. Loss: 0.4942, Accuracy: 90.11%\n",
      "valid. Loss: 1.1204, Accuracy: 71.42%\n",
      "Completed in 0m 57s\n",
      "-------------- epoch 30 ----------------\n",
      "train. Loss: 0.4776, Accuracy: 90.89%\n",
      "valid. Loss: 1.1036, Accuracy: 72.13%\n",
      "Completed in 0m 57s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import copy\n",
    " \n",
    "def train_baseline(model ,train_loader, val_loader, optimizer, num_epochs = 30):\n",
    "    best_acc = 0.0  \n",
    "    best_model_wts = copy.deepcopy(model.state_dict()) \n",
    " \n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        since = time.time()  \n",
    "        train(model, train_loader, optimizer)\n",
    "        train_loss, train_acc = evaluate(model, train_loader) \n",
    "        val_loss, val_acc = evaluate(model, val_loader)\n",
    "        \n",
    "        if val_acc > best_acc: \n",
    "            best_acc = val_acc \n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        \n",
    "        time_elapsed = time.time() - since \n",
    "        print('-------------- epoch {} ----------------'.format(epoch))\n",
    "        print('train. Loss: {:.4f}, Accuracy: {:.2f}%'.format(train_loss, train_acc))   \n",
    "        print('valid. Loss: {:.4f}, Accuracy: {:.2f}%'.format(val_loss, val_acc))\n",
    "        print('Completed in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60)) \n",
    "    model.load_state_dict(best_model_wts)  \n",
    "    return model\n",
    " \n",
    "\n",
    "base = train_baseline(model_base, train_loader, val_loader, optimizer, EPOCH)  \t #(16)\n",
    "torch.save(base,'baseline.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5671419f",
   "metadata": {},
   "source": [
    "-------------- epoch 1 ----------------\n",
    "train. Loss: 4.4294, Accuracy: 14.33%\n",
    "valid. Loss: 4.3355, Accuracy: 14.71%\n",
    "Completed in 0m 58s\n",
    "-------------- epoch 2 ----------------\n",
    "train. Loss: 3.1777, Accuracy: 34.09%\n",
    "valid. Loss: 3.0201, Accuracy: 34.27%\n",
    "Completed in 0m 56s\n",
    "-------------- epoch 3 ----------------\n",
    "train. Loss: 2.7054, Accuracy: 43.25%\n",
    "valid. Loss: 2.5589, Accuracy: 44.36%\n",
    "Completed in 0m 56s\n",
    "-------------- epoch 4 ----------------\n",
    "train. Loss: 2.2388, Accuracy: 52.13%\n",
    "valid. Loss: 2.1472, Accuracy: 51.87%\n",
    "Completed in 0m 56s\n",
    "-------------- epoch 5 ----------------\n",
    "train. Loss: 2.0219, Accuracy: 56.29%\n",
    "valid. Loss: 1.9648, Accuracy: 54.98%\n",
    "Completed in 0m 56s\n",
    "-------------- epoch 6 ----------------\n",
    "train. Loss: 1.8230, Accuracy: 61.03%\n",
    "valid. Loss: 1.8225, Accuracy: 58.13%\n",
    "Completed in 0m 56s\n",
    "-------------- epoch 7 ----------------\n",
    "train. Loss: 1.6194, Accuracy: 64.34%\n",
    "valid. Loss: 1.6485, Accuracy: 60.18%\n",
    "Completed in 0m 56s\n",
    "-------------- epoch 8 ----------------\n",
    "train. Loss: 1.4960, Accuracy: 66.84%\n",
    "valid. Loss: 1.5936, Accuracy: 61.29%\n",
    "Completed in 0m 56s\n",
    "-------------- epoch 9 ----------------\n",
    "train. Loss: 1.4137, Accuracy: 69.63%\n",
    "valid. Loss: 1.5355, Accuracy: 63.38%\n",
    "Completed in 0m 56s\n",
    "-------------- epoch 10 ----------------\n",
    "train. Loss: 1.2893, Accuracy: 71.15%\n",
    "valid. Loss: 1.4372, Accuracy: 64.89%\n",
    "Completed in 0m 56s\n",
    "-------------- epoch 11 ----------------\n",
    "train. Loss: 1.2025, Accuracy: 73.50%\n",
    "valid. Loss: 1.3969, Accuracy: 66.36%\n",
    "Completed in 0m 56s\n",
    "-------------- epoch 12 ----------------\n",
    "train. Loss: 1.1236, Accuracy: 75.15%\n",
    "valid. Loss: 1.3564, Accuracy: 66.98%\n",
    "Completed in 0m 56s\n",
    "-------------- epoch 13 ----------------\n",
    "train. Loss: 1.0651, Accuracy: 76.99%\n",
    "valid. Loss: 1.3304, Accuracy: 68.13%\n",
    "Completed in 0m 56s\n",
    "-------------- epoch 14 ----------------\n",
    "train. Loss: 0.9825, Accuracy: 79.04%\n",
    "valid. Loss: 1.3052, Accuracy: 68.44%\n",
    "Completed in 0m 58s\n",
    "-------------- epoch 15 ----------------\n",
    "train. Loss: 0.9596, Accuracy: 79.87%\n",
    "valid. Loss: 1.3050, Accuracy: 68.67%\n",
    "Completed in 0m 57s\n",
    "-------------- epoch 16 ----------------\n",
    "train. Loss: 0.9461, Accuracy: 79.48%\n",
    "valid. Loss: 1.2846, Accuracy: 69.56%\n",
    "Completed in 0m 56s\n",
    "-------------- epoch 17 ----------------\n",
    "train. Loss: 0.8751, Accuracy: 80.50%\n",
    "valid. Loss: 1.2499, Accuracy: 69.51%\n",
    "Completed in 0m 56s\n",
    "-------------- epoch 18 ----------------\n",
    "train. Loss: 0.7920, Accuracy: 83.20%\n",
    "valid. Loss: 1.2223, Accuracy: 70.22%\n",
    "Completed in 0m 56s\n",
    "-------------- epoch 19 ----------------\n",
    "train. Loss: 0.7752, Accuracy: 83.62%\n",
    "valid. Loss: 1.2178, Accuracy: 70.89%\n",
    "Completed in 0m 56s\n",
    "-------------- epoch 20 ----------------\n",
    "train. Loss: 0.7400, Accuracy: 84.71%\n",
    "valid. Loss: 1.2108, Accuracy: 69.29%\n",
    "Completed in 0m 56s\n",
    "-------------- epoch 21 ----------------\n",
    "train. Loss: 0.7018, Accuracy: 85.17%\n",
    "valid. Loss: 1.1892, Accuracy: 70.93%\n",
    "Completed in 0m 56s\n",
    "-------------- epoch 22 ----------------\n",
    "train. Loss: 0.6753, Accuracy: 85.93%\n",
    "valid. Loss: 1.1549, Accuracy: 71.87%\n",
    "Completed in 0m 56s\n",
    "-------------- epoch 23 ----------------\n",
    "train. Loss: 0.6540, Accuracy: 86.57%\n",
    "valid. Loss: 1.1979, Accuracy: 70.76%\n",
    "Completed in 0m 56s\n",
    "-------------- epoch 24 ----------------\n",
    "train. Loss: 0.6305, Accuracy: 86.92%\n",
    "valid. Loss: 1.1494, Accuracy: 71.33%\n",
    "Completed in 0m 56s\n",
    "-------------- epoch 25 ----------------\n",
    "train. Loss: 0.5849, Accuracy: 88.23%\n",
    "valid. Loss: 1.1211, Accuracy: 71.91%\n",
    "Completed in 0m 57s\n",
    "-------------- epoch 26 ----------------\n",
    "train. Loss: 0.5858, Accuracy: 88.00%\n",
    "valid. Loss: 1.1152, Accuracy: 71.78%\n",
    "Completed in 0m 57s\n",
    "-------------- epoch 27 ----------------\n",
    "train. Loss: 0.5126, Accuracy: 89.67%\n",
    "valid. Loss: 1.1037, Accuracy: 72.18%\n",
    "Completed in 0m 57s\n",
    "-------------- epoch 28 ----------------\n",
    "train. Loss: 0.5210, Accuracy: 89.61%\n",
    "valid. Loss: 1.1303, Accuracy: 71.73%\n",
    "Completed in 0m 56s\n",
    "-------------- epoch 29 ----------------\n",
    "train. Loss: 0.4942, Accuracy: 90.11%\n",
    "valid. Loss: 1.1204, Accuracy: 71.42%\n",
    "Completed in 0m 57s\n",
    "-------------- epoch 30 ----------------\n",
    "train. Loss: 0.4776, Accuracy: 90.89%\n",
    "valid. Loss: 1.1036, Accuracy: 72.13%\n",
    "Completed in 0m 57s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76568ebd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17516\\555056709.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'./dataset'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m image_datasets = {x: ImageFolder(root = os.path.join(data_dir, x),\n\u001b[1;32m---> 20\u001b[1;33m                                 transform=data_tansforms[x]) for x in ['train', 'valid']}\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[0mdataloaders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_datasets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'valid'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mdataset_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_datasets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'valid'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17516\\555056709.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'./dataset'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m image_datasets = {x: ImageFolder(root = os.path.join(data_dir, x),\n\u001b[1;32m---> 20\u001b[1;33m                                 transform=data_tansforms[x]) for x in ['train', 'valid']}\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[0mdataloaders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_datasets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'valid'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mdataset_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_datasets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'valid'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize([64, 64]),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.RandomCrop(52),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'valid': transforms.Compose([\n",
    "        transforms.Resize([64, 64]),\n",
    "        transforms.RandomCrop(52),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "data_dir = './dataset'\n",
    "image_datasets = {x: ImageFolder(root = os.path.join(data_dir, x),\n",
    "                                transform=data_tansforms[x]) for x in ['train', 'valid']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=BATCH_SIZE, shuffle=True, num_workers=4) for x in ['train', 'valid']} \n",
    "dataset_size = {x: len(image_datasets[x]) for x in ['train', 'valid']}\n",
    "\n",
    "class_name = image_datasets['train'].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf756c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
