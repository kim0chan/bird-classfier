{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eeb8caf2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kyc_o\\anaconda3\\envs\\dl\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: \n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device('cuda' if USE_CUDA else 'cpu')\n",
    "print(DEVICE)\n",
    "\n",
    "BATCH_SIZE = 224\n",
    "EPOCH = 30\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "transform_base = transforms.Compose([transforms.Resize((64, 64)), transforms.ToTensor()])\n",
    "\n",
    "train_dataset = ImageFolder(root='../dataset/train_', transform=transform_base)\n",
    "val_dataset = ImageFolder(root='../dataset/valid_', transform=transform_base)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62e18963",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        \n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding = 1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding = 1)\n",
    "        self.conv3 = nn.Conv2d(64, 64, 3, padding = 1)\n",
    "        \n",
    "        self.fc1 = nn.Linear(4096, 512)\n",
    "        self.fc2 = nn.Linear(512, 450)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = F.dropout(x, p=0.25, training=self.training)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = F.dropout(x, p=0.25, training=self.training)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = F.dropout(x, p=0.25, training=self.training)\n",
    "        \n",
    "        x = x.view(-1, 4096)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "model_base = Net().to(DEVICE)\n",
    "optimizer = optim.Adam(model_base.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f36d902",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63d27846",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "            output = model(data)\n",
    "            \n",
    "            \n",
    "            test_loss += F.cross_entropy(output, target, reduction='sum').item()\n",
    "            \n",
    "            \n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            \n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "        return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20176804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- epoch 1 ----------------\n",
      "train. Loss: 5.8366, Accuracy: 50.00%\n",
      "valid. Loss: 5.8366, Accuracy: 50.00%\n",
      "Completed in 0m 7s\n",
      "-------------- epoch 2 ----------------\n",
      "train. Loss: 5.0580, Accuracy: 50.00%\n",
      "valid. Loss: 5.0580, Accuracy: 50.00%\n",
      "Completed in 0m 4s\n",
      "-------------- epoch 3 ----------------\n",
      "train. Loss: 3.3770, Accuracy: 50.00%\n",
      "valid. Loss: 3.3770, Accuracy: 50.00%\n",
      "Completed in 0m 5s\n",
      "-------------- epoch 4 ----------------\n",
      "train. Loss: 2.2621, Accuracy: 50.00%\n",
      "valid. Loss: 2.2621, Accuracy: 50.00%\n",
      "Completed in 0m 4s\n",
      "-------------- epoch 5 ----------------\n",
      "train. Loss: 1.7648, Accuracy: 50.00%\n",
      "valid. Loss: 1.7648, Accuracy: 50.00%\n",
      "Completed in 0m 4s\n",
      "-------------- epoch 6 ----------------\n",
      "train. Loss: 1.5494, Accuracy: 50.00%\n",
      "valid. Loss: 1.5494, Accuracy: 50.00%\n",
      "Completed in 0m 5s\n",
      "-------------- epoch 7 ----------------\n",
      "train. Loss: 1.8458, Accuracy: 33.33%\n",
      "valid. Loss: 1.8458, Accuracy: 33.33%\n",
      "Completed in 0m 5s\n",
      "-------------- epoch 8 ----------------\n",
      "train. Loss: 2.0079, Accuracy: 33.33%\n",
      "valid. Loss: 2.0079, Accuracy: 33.33%\n",
      "Completed in 0m 5s\n",
      "-------------- epoch 9 ----------------\n",
      "train. Loss: 2.1522, Accuracy: 33.33%\n",
      "valid. Loss: 2.1522, Accuracy: 33.33%\n",
      "Completed in 0m 4s\n",
      "-------------- epoch 10 ----------------\n",
      "train. Loss: 2.1317, Accuracy: 33.33%\n",
      "valid. Loss: 2.1317, Accuracy: 33.33%\n",
      "Completed in 0m 4s\n",
      "-------------- epoch 11 ----------------\n",
      "train. Loss: 1.8076, Accuracy: 50.00%\n",
      "valid. Loss: 1.8076, Accuracy: 50.00%\n",
      "Completed in 0m 5s\n",
      "-------------- epoch 12 ----------------\n",
      "train. Loss: 1.4816, Accuracy: 50.00%\n",
      "valid. Loss: 1.4816, Accuracy: 50.00%\n",
      "Completed in 0m 4s\n",
      "-------------- epoch 13 ----------------\n",
      "train. Loss: 1.2643, Accuracy: 50.00%\n",
      "valid. Loss: 1.2643, Accuracy: 50.00%\n",
      "Completed in 0m 5s\n",
      "-------------- epoch 14 ----------------\n",
      "train. Loss: 1.1833, Accuracy: 50.00%\n",
      "valid. Loss: 1.1833, Accuracy: 50.00%\n",
      "Completed in 0m 4s\n",
      "-------------- epoch 15 ----------------\n",
      "train. Loss: 1.1461, Accuracy: 50.00%\n",
      "valid. Loss: 1.1461, Accuracy: 50.00%\n",
      "Completed in 0m 4s\n",
      "-------------- epoch 16 ----------------\n",
      "train. Loss: 1.1227, Accuracy: 50.00%\n",
      "valid. Loss: 1.1227, Accuracy: 50.00%\n",
      "Completed in 0m 4s\n",
      "-------------- epoch 17 ----------------\n",
      "train. Loss: 1.1382, Accuracy: 50.00%\n",
      "valid. Loss: 1.1382, Accuracy: 50.00%\n",
      "Completed in 0m 5s\n",
      "-------------- epoch 18 ----------------\n",
      "train. Loss: 1.2045, Accuracy: 50.00%\n",
      "valid. Loss: 1.2045, Accuracy: 50.00%\n",
      "Completed in 0m 5s\n",
      "-------------- epoch 19 ----------------\n",
      "train. Loss: 1.2893, Accuracy: 50.00%\n",
      "valid. Loss: 1.2893, Accuracy: 50.00%\n",
      "Completed in 0m 5s\n",
      "-------------- epoch 20 ----------------\n",
      "train. Loss: 1.3921, Accuracy: 50.00%\n",
      "valid. Loss: 1.3921, Accuracy: 50.00%\n",
      "Completed in 0m 5s\n",
      "-------------- epoch 21 ----------------\n",
      "train. Loss: 1.5147, Accuracy: 50.00%\n",
      "valid. Loss: 1.5147, Accuracy: 50.00%\n",
      "Completed in 0m 5s\n",
      "-------------- epoch 22 ----------------\n",
      "train. Loss: 1.6006, Accuracy: 50.00%\n",
      "valid. Loss: 1.6006, Accuracy: 50.00%\n",
      "Completed in 0m 5s\n",
      "-------------- epoch 23 ----------------\n",
      "train. Loss: 1.5808, Accuracy: 66.67%\n",
      "valid. Loss: 1.5808, Accuracy: 66.67%\n",
      "Completed in 0m 5s\n",
      "-------------- epoch 24 ----------------\n",
      "train. Loss: 1.5056, Accuracy: 66.67%\n",
      "valid. Loss: 1.5056, Accuracy: 66.67%\n",
      "Completed in 0m 5s\n",
      "-------------- epoch 25 ----------------\n",
      "train. Loss: 1.4526, Accuracy: 83.33%\n",
      "valid. Loss: 1.4526, Accuracy: 83.33%\n",
      "Completed in 0m 5s\n",
      "-------------- epoch 26 ----------------\n",
      "train. Loss: 1.3784, Accuracy: 66.67%\n",
      "valid. Loss: 1.3784, Accuracy: 66.67%\n",
      "Completed in 0m 5s\n",
      "-------------- epoch 27 ----------------\n",
      "train. Loss: 1.2362, Accuracy: 66.67%\n",
      "valid. Loss: 1.2362, Accuracy: 66.67%\n",
      "Completed in 0m 5s\n",
      "-------------- epoch 28 ----------------\n",
      "train. Loss: 1.0773, Accuracy: 66.67%\n",
      "valid. Loss: 1.0773, Accuracy: 66.67%\n",
      "Completed in 0m 4s\n",
      "-------------- epoch 29 ----------------\n",
      "train. Loss: 1.0186, Accuracy: 66.67%\n",
      "valid. Loss: 1.0186, Accuracy: 66.67%\n",
      "Completed in 0m 4s\n",
      "-------------- epoch 30 ----------------\n",
      "train. Loss: 1.0136, Accuracy: 66.67%\n",
      "valid. Loss: 1.0136, Accuracy: 66.67%\n",
      "Completed in 0m 5s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import copy\n",
    " \n",
    "def train_baseline(model ,train_loader, val_loader, optimizer, num_epochs = 30):\n",
    "    best_acc = 0.0  \n",
    "    best_model_wts = copy.deepcopy(model.state_dict()) \n",
    " \n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        since = time.time()  \n",
    "        train(model, train_loader, optimizer)\n",
    "        train_loss, train_acc = evaluate(model, train_loader) \n",
    "        val_loss, val_acc = evaluate(model, val_loader)\n",
    "        \n",
    "        if val_acc > best_acc: \n",
    "            best_acc = val_acc \n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        \n",
    "        time_elapsed = time.time() - since \n",
    "        print('-------------- epoch {} ----------------'.format(epoch))\n",
    "        print('train. Loss: {:.4f}, Accuracy: {:.2f}%'.format(train_loss, train_acc))   \n",
    "        print('valid. Loss: {:.4f}, Accuracy: {:.2f}%'.format(val_loss, val_acc))\n",
    "        print('Completed in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60)) \n",
    "    model.load_state_dict(best_model_wts)  \n",
    "    return model\n",
    " \n",
    "\n",
    "base = train_baseline(model_base, train_loader, val_loader, optimizer, EPOCH)  \t #(16)\n",
    "torch.save(base,'baseline.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7954f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor([[[[0.5333, 0.5098, 0.4745,  ..., 0.2078, 0.2118, 0.2157],\n",
      "          [0.5294, 0.5059, 0.4745,  ..., 0.2078, 0.2078, 0.2118],\n",
      "          [0.5216, 0.5020, 0.4784,  ..., 0.2118, 0.2078, 0.2078],\n",
      "          ...,\n",
      "          [0.2824, 0.3804, 0.4353,  ..., 0.1137, 0.1059, 0.1059],\n",
      "          [0.3098, 0.3569, 0.4431,  ..., 0.1176, 0.1020, 0.1020],\n",
      "          [0.3529, 0.3569, 0.4431,  ..., 0.1608, 0.1098, 0.1020]],\n",
      "\n",
      "         [[0.6353, 0.6118, 0.5804,  ..., 0.2157, 0.2196, 0.2235],\n",
      "          [0.6275, 0.6078, 0.5765,  ..., 0.2157, 0.2157, 0.2196],\n",
      "          [0.6157, 0.5961, 0.5765,  ..., 0.2196, 0.2157, 0.2157],\n",
      "          ...,\n",
      "          [0.3059, 0.4039, 0.4510,  ..., 0.1098, 0.1020, 0.1020],\n",
      "          [0.3333, 0.3804, 0.4588,  ..., 0.1137, 0.0980, 0.0980],\n",
      "          [0.3765, 0.3804, 0.4588,  ..., 0.1569, 0.1059, 0.0980]],\n",
      "\n",
      "         [[0.5373, 0.4941, 0.4314,  ..., 0.2039, 0.2078, 0.2118],\n",
      "          [0.5373, 0.4980, 0.4392,  ..., 0.2039, 0.2039, 0.2078],\n",
      "          [0.5412, 0.5020, 0.4510,  ..., 0.2078, 0.2039, 0.2039],\n",
      "          ...,\n",
      "          [0.2471, 0.3686, 0.4510,  ..., 0.1333, 0.1255, 0.1255],\n",
      "          [0.2784, 0.3333, 0.4549,  ..., 0.1373, 0.1216, 0.1216],\n",
      "          [0.3255, 0.3255, 0.4510,  ..., 0.1804, 0.1294, 0.1176]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 0.9922, 0.9961, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 0.9804, 1.0000, 1.0000],\n",
      "          ...,\n",
      "          [0.7294, 0.4745, 0.5020,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [0.8235, 0.7176, 0.6902,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [0.8392, 0.7843, 0.7255,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "         [[1.0000, 1.0000, 1.0000,  ..., 0.9961, 0.9961, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 0.9961, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 0.9804, 1.0000, 1.0000],\n",
      "          ...,\n",
      "          [0.6745, 0.4157, 0.4471,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [0.7843, 0.6706, 0.6392,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [0.8118, 0.7412, 0.6706,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "         [[1.0000, 1.0000, 1.0000,  ..., 0.9961, 1.0000, 0.9961],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 0.9922, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 0.9647, 0.9961, 1.0000],\n",
      "          ...,\n",
      "          [0.6039, 0.3804, 0.3961,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [0.7490, 0.6314, 0.5333,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [0.7725, 0.6784, 0.5059,  ..., 1.0000, 1.0000, 1.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.6667, 0.6706, 0.6784,  ..., 0.3725, 0.3647, 0.3529],\n",
      "          [0.6549, 0.6627, 0.6706,  ..., 0.3529, 0.3490, 0.3451],\n",
      "          [0.6392, 0.6471, 0.6549,  ..., 0.3373, 0.3373, 0.3373],\n",
      "          ...,\n",
      "          [0.2314, 0.2275, 0.2314,  ..., 0.0824, 0.0863, 0.1020],\n",
      "          [0.2353, 0.2275, 0.2275,  ..., 0.0863, 0.0902, 0.0902],\n",
      "          [0.2353, 0.2314, 0.2275,  ..., 0.1059, 0.0980, 0.0902]],\n",
      "\n",
      "         [[0.7804, 0.7843, 0.7843,  ..., 0.4471, 0.4392, 0.4392],\n",
      "          [0.7686, 0.7765, 0.7765,  ..., 0.4275, 0.4235, 0.4275],\n",
      "          [0.7529, 0.7608, 0.7686,  ..., 0.4118, 0.4118, 0.4157],\n",
      "          ...,\n",
      "          [0.2824, 0.2784, 0.2824,  ..., 0.0392, 0.0392, 0.0510],\n",
      "          [0.2863, 0.2784, 0.2784,  ..., 0.0392, 0.0392, 0.0392],\n",
      "          [0.2863, 0.2824, 0.2784,  ..., 0.0510, 0.0471, 0.0392]],\n",
      "\n",
      "         [[0.5608, 0.5647, 0.5608,  ..., 0.3686, 0.3608, 0.3647],\n",
      "          [0.5490, 0.5569, 0.5569,  ..., 0.3490, 0.3451, 0.3529],\n",
      "          [0.5412, 0.5451, 0.5529,  ..., 0.3333, 0.3333, 0.3373],\n",
      "          ...,\n",
      "          [0.2471, 0.2431, 0.2471,  ..., 0.0196, 0.0157, 0.0275],\n",
      "          [0.2510, 0.2431, 0.2431,  ..., 0.0157, 0.0157, 0.0157],\n",
      "          [0.2510, 0.2471, 0.2510,  ..., 0.0275, 0.0235, 0.0157]]],\n",
      "\n",
      "\n",
      "        [[[0.6392, 0.6392, 0.5176,  ..., 0.5333, 0.6039, 0.6314],\n",
      "          [0.5529, 0.6157, 0.4549,  ..., 0.5176, 0.5843, 0.6118],\n",
      "          [0.4941, 0.5647, 0.4118,  ..., 0.4863, 0.5608, 0.5961],\n",
      "          ...,\n",
      "          [0.2431, 0.2196, 0.2157,  ..., 0.3804, 0.3961, 0.3961],\n",
      "          [0.2118, 0.2039, 0.1961,  ..., 0.3882, 0.4000, 0.4039],\n",
      "          [0.1922, 0.1882, 0.1843,  ..., 0.3922, 0.4039, 0.4039]],\n",
      "\n",
      "         [[0.6667, 0.6471, 0.5098,  ..., 0.5647, 0.6314, 0.6588],\n",
      "          [0.5882, 0.6275, 0.4471,  ..., 0.5529, 0.6118, 0.6392],\n",
      "          [0.5333, 0.5804, 0.4000,  ..., 0.5216, 0.5882, 0.6235],\n",
      "          ...,\n",
      "          [0.2157, 0.1922, 0.1843,  ..., 0.4157, 0.4471, 0.4510],\n",
      "          [0.1843, 0.1765, 0.1647,  ..., 0.4471, 0.4471, 0.4431],\n",
      "          [0.1647, 0.1608, 0.1529,  ..., 0.4392, 0.4471, 0.4510]],\n",
      "\n",
      "         [[0.6314, 0.6235, 0.4784,  ..., 0.5098, 0.6000, 0.6235],\n",
      "          [0.5451, 0.6000, 0.3922,  ..., 0.4941, 0.5765, 0.6078],\n",
      "          [0.4706, 0.5333, 0.3294,  ..., 0.4510, 0.5490, 0.5922],\n",
      "          ...,\n",
      "          [0.1451, 0.1176, 0.1137,  ..., 0.2824, 0.2941, 0.2980],\n",
      "          [0.1098, 0.1020, 0.0902,  ..., 0.2863, 0.2941, 0.3020],\n",
      "          [0.0902, 0.0863, 0.0784,  ..., 0.2980, 0.3059, 0.3020]]],\n",
      "\n",
      "\n",
      "        [[[0.4588, 0.4471, 0.4353,  ..., 0.5255, 0.5216, 0.5216],\n",
      "          [0.4510, 0.4392, 0.4314,  ..., 0.5020, 0.5020, 0.4980],\n",
      "          [0.4431, 0.4353, 0.4314,  ..., 0.4784, 0.4745, 0.4745],\n",
      "          ...,\n",
      "          [0.3765, 0.3725, 0.3647,  ..., 0.3725, 0.3725, 0.3804],\n",
      "          [0.3804, 0.3725, 0.3686,  ..., 0.3765, 0.3765, 0.3765],\n",
      "          [0.3765, 0.3765, 0.3725,  ..., 0.3686, 0.3451, 0.3255]],\n",
      "\n",
      "         [[0.4510, 0.4431, 0.4392,  ..., 0.5294, 0.5294, 0.5255],\n",
      "          [0.4431, 0.4392, 0.4353,  ..., 0.5098, 0.5059, 0.5059],\n",
      "          [0.4431, 0.4392, 0.4353,  ..., 0.4863, 0.4824, 0.4824],\n",
      "          ...,\n",
      "          [0.3608, 0.3569, 0.3529,  ..., 0.3804, 0.3725, 0.3725],\n",
      "          [0.3647, 0.3569, 0.3529,  ..., 0.3686, 0.3725, 0.3765],\n",
      "          [0.3608, 0.3608, 0.3569,  ..., 0.3647, 0.3490, 0.3373]],\n",
      "\n",
      "         [[0.4039, 0.3922, 0.3843,  ..., 0.5412, 0.5373, 0.5373],\n",
      "          [0.3961, 0.3882, 0.3804,  ..., 0.5059, 0.5020, 0.4980],\n",
      "          [0.3961, 0.3843, 0.3804,  ..., 0.4667, 0.4627, 0.4627],\n",
      "          ...,\n",
      "          [0.2039, 0.2039, 0.2000,  ..., 0.3490, 0.3569, 0.3490],\n",
      "          [0.2118, 0.2078, 0.2039,  ..., 0.3451, 0.3490, 0.3490],\n",
      "          [0.2118, 0.2118, 0.2078,  ..., 0.3333, 0.2941, 0.2824]]],\n",
      "\n",
      "\n",
      "        [[[0.1294, 0.1412, 0.2000,  ..., 0.1020, 0.0824, 0.1961],\n",
      "          [0.1294, 0.1176, 0.1412,  ..., 0.1922, 0.1451, 0.1451],\n",
      "          [0.0706, 0.0667, 0.0667,  ..., 0.1882, 0.2392, 0.2392],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.1255, 0.1451, 0.1608],\n",
      "          [0.0000, 0.0039, 0.0000,  ..., 0.1373, 0.1490, 0.1490],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.1412, 0.1490, 0.1412]],\n",
      "\n",
      "         [[0.0275, 0.0471, 0.0902,  ..., 0.1216, 0.1216, 0.2471],\n",
      "          [0.0275, 0.0314, 0.0510,  ..., 0.2314, 0.1961, 0.2039],\n",
      "          [0.0078, 0.0157, 0.0118,  ..., 0.2510, 0.2980, 0.3059],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.2510, 0.2549, 0.2471],\n",
      "          [0.0039, 0.0000, 0.0000,  ..., 0.2510, 0.2510, 0.2392],\n",
      "          [0.0039, 0.0000, 0.0000,  ..., 0.2314, 0.2431, 0.2392]],\n",
      "\n",
      "         [[0.0118, 0.0157, 0.0157,  ..., 0.1020, 0.0824, 0.2000],\n",
      "          [0.0118, 0.0157, 0.0235,  ..., 0.2392, 0.1843, 0.1882],\n",
      "          [0.0078, 0.0157, 0.0196,  ..., 0.2784, 0.3098, 0.3137],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0078,  ..., 0.0157, 0.0235, 0.0235],\n",
      "          [0.0000, 0.0000, 0.0078,  ..., 0.0235, 0.0235, 0.0157],\n",
      "          [0.0000, 0.0000, 0.0039,  ..., 0.0118, 0.0157, 0.0118]]]])\n",
      "tensor([1, 2, 1, 2, 2, 0])\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        print(batch_idx)\n",
    "        print(data)\n",
    "        print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90da6ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(train_loader)['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a33dbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
